{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install SDG\n",
    "```bash \n",
    "git clone https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub.git\n",
    "cd sdg_hub\n",
    "pip install .[examples]\n",
    "```\n",
    "**⚠️ If you haven't already, run the document pre-processing notebook to create the seed data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First Party\n",
    "from sdg_hub import Flow, FlowRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to run the flow with async mode\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDG\n",
    "- This will create knowledge flow from provided yaml file\n",
    "- We will run this on small dataset for demo purposes\n",
    "- For large scale generation, please use the python command provided in the next cell\n",
    "- You can analyze the generated data to ensure the quality is similar to proivded QnA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover the available generation flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-discover all available flows (no setup needed!)\n",
    "FlowRegistry.discover_flows()\n",
    "\n",
    "# List available flows\n",
    "flows = FlowRegistry.list_flows()\n",
    "print(f\"Available flows: {flows}\")\n",
    "\n",
    "# You can also search the flows by tag\n",
    "qa_flows = FlowRegistry.search_flows(tag=\"question-generation\")\n",
    "print(f\"QA flows: {qa_flows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\" flow.\n",
    "# For loading the flow simply use the fullname to load it\n",
    "flow_name = (\n",
    "    \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    ")\n",
    "flow_path = FlowRegistry.get_flow_path(flow_name)\n",
    "flow = Flow.from_yaml(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the recommended model and set the model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_model_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can dynamically change the model without having to change the flow yaml file.\n",
    "# Configure the flow to use a vllm model hosted at localhost:8000/v1.\n",
    "flow.set_model_config(\n",
    "    model=\"hosted_vllm/meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    api_base=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data\n",
    "number_of_samples = 2\n",
    "seed_data_dir = f\"sdg_demo_output/\"\n",
    "ds = load_dataset(\"json\", data_files=f\"{seed_data_dir}/seed_data.jsonl\", split=\"train\")\n",
    "ds = ds.shuffle(seed=42).select(range(number_of_samples))\n",
    "ds = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "generated_data = flow.generate(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the generated data into training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from knowledge_utils import create_knowledge_regular_ds, create_knowledge_pretraining_ds\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "output_dir = f\"sdg_demo_output/\"\n",
    "\n",
    "\n",
    "# Create Pretraining Knowledge Dataset (Also known as Phase 0.7/Phase 7)\n",
    "instructlab_phase_1_ds = create_knowledge_pretraining_ds(generated_data)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "instructlab_phase_1_ds.to_json(\n",
    "    f\"{output_dir}/instructlab_phase_1_ds.jsonl\", orient=\"records\", lines=True\n",
    ")\n",
    "\n",
    "# Create Regular Knowledge Dataset (Also known as Phase 1.0/Phase 10)\n",
    "instructlab_phase_2_ds = create_knowledge_regular_ds(generated_data)\n",
    "\n",
    "# Mix the pre-computed skills with the regular knowledge dataset. If more than one dataset were generated simply add those in this concatenation stage.\n",
    "# If you have any generated instruction data, that can be also mixed in this stage. If you only have generated skills phase 07 generation and training can be skipped.\n",
    "instructlab_phase_2_ds.to_json(\n",
    "    f\"{output_dir}/instructlab_phase_2_ds.jsonl\", orient=\"records\", lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have any other instruction tuning datasets you can mix with phase 2 dataset.\n",
    "instruction_tuning_dataset_path = \"<Your instruction tuning dataset path>\"\n",
    "instruction_tuning_dataset = load_dataset(\n",
    "    \"json\", data_files=instruction_tuning_dataset_path, split=\"train\"\n",
    ")\n",
    "instructlab_phase_2_ds = concatenate_datasets(\n",
    "    [instructlab_phase_2_ds, instruction_tuning_dataset]\n",
    ")\n",
    "instructlab_phase_2_ds.to_json(\n",
    "    f\"{output_dir}/instructlab_phase_2_ds.jsonl\", orient=\"records\", lines=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
