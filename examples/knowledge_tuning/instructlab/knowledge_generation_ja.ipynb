{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install SDG\n",
    "```bash \n",
    "git clone https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub.git\n",
    "cd sdg_hub\n",
    "pip install .[examples]\n",
    "```\n",
    "**⚠️ If you haven't already, run the document pre-processing notebook to create the seed data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party\n",
    "from datasets import load_dataset\n",
    "\n",
    "# First Party\n",
    "from sdg_hub import Flow, FlowRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to run the flow with async mode\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"\"  # an arbitrary label for seed data (can be empty)\n",
    "\n",
    "data_lang = \"ja\"  # for Japanese seed data\n",
    "# data_lang = \"\"\n",
    "\n",
    "repeat_times = 1\n",
    "# repeat_times = 5  # for using the same seed data multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_name = f\"_{data_name}\" if data_name is not None and len(data_name) > 0 else \"\"\n",
    "_repeat_times = f\"_r{repeat_times}\" if repeat_times > 1 else \"\"\n",
    "\n",
    "sdg_demo_output = \"sdg_demo_output\"\n",
    "\n",
    "seed_data_path = f\"{sdg_demo_output}{_data_name}/seed_data.jsonl\"\n",
    "output_dir_prefix = f\"{sdg_demo_output}{_data_name}{_repeat_times}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace model name\n",
    "phi4_model_name_hf = \"microsoft/phi-4\"\n",
    "llama3_model_name_hf = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "mixtral_model_name_hf = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "# Model short name\n",
    "phi4_short_name = \"phi4\"\n",
    "llama3_short_name = \"llama3\"\n",
    "mixtral_short_name = \"mixtral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a model\n",
    "short_name = phi4_short_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_name == phi4_short_name:\n",
    "    model_name_hf = phi4_model_name_hf\n",
    "elif short_name == llama3_short_name:\n",
    "    model_name_hf = llama3_model_name_hf\n",
    "elif short_name == mixtral_short_name:\n",
    "    model_name_hf = mixtral_model_name_hf\n",
    "else:\n",
    "    raise ValueError(f\"Invalid short_name: {short_name}. Must be one of: {phi4_short_name}, {llama3_short_name}, {mixtral_short_name}\")\n",
    "\n",
    "output_dir = f\"{output_dir_prefix}_{short_name}\"  # for continued execution after failure\n",
    "# output_dir = f\"{output_dir_prefix}_{short_name}_{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_mode = True\n",
    "# async_mode = False  # single worker\n",
    "timeout = 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = f\"{output_dir}_ckpt\"\n",
    "# See https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub/blob/main/docs/blocks/llm-blocks.md#async-processing--concurrency-control\n",
    "save_freq = 10  # checkpoint interval (in request)\n",
    "max_concurrency = 20  # (async_mode only) max in-flight requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SDG\n",
    "- This will create knowledge flow from provided yaml file\n",
    "- We will run this on small dataset for demo purposes\n",
    "- For large scale generation, please use the python command provided in the next cell\n",
    "- You can analyze the generated data to ensure the quality is similar to provided QnA pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover the available generation flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-discover all available flows (no setup needed!)\n",
    "FlowRegistry.discover_flows()\n",
    "\n",
    "# List available flows\n",
    "flows = FlowRegistry.list_flows()\n",
    "print(f\"Available flows: {flows}\")\n",
    "\n",
    "# You can also search the flows by tag\n",
    "qa_flows = FlowRegistry.search_flows(tag=\"question-generation\")\n",
    "print(f\"QA flows: {qa_flows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\" flow.\n",
    "# For loading the flow simply use the fullname to load it\n",
    "if data_lang == \"ja\":\n",
    "    flow_name = \"Advanced Japanese Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    "else:\n",
    "    flow_name = \"Advanced Document Grounded Question-Answer Generation Flow for Knowledge Tuning\"\n",
    "flow_path = FlowRegistry.get_flow_path(flow_name)\n",
    "flow = Flow.from_yaml(flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the recommended model and set the model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.get_model_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can dynamically change the model without having to change the flow yaml file.\n",
    "# Configure the flow to use a vllm model hosted at localhost:8000/v1. \n",
    "flow.set_model_config(\n",
    "    model=f\"hosted_vllm/{model_name_hf}\",\n",
    "    api_base=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    "    async_mode=async_mode,\n",
    "    timeout=timeout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and prepare seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seed data\n",
    "ds = load_dataset('json', data_files=seed_data_path, split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat (duplicate) seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if repeat_times > 1:\n",
    "    ds = ds.repeat(repeat_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) sample seed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 2\n",
    "ds = ds.select(range(number_of_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add seed id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add seed_id column to preserve repetition in seed data\n",
    "# See https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub/blob/42650f1340a2d3576818d68e05508dfe2a8d04bd/src/sdg_hub/checkpointer.py#L103\n",
    "ds = ds.add_column(\"seed_id\", list(range(len(ds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(ds)} seed data\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "generated_data = flow.generate(ds, checkpoint_dir=checkpoint_dir, save_freq=save_freq, max_concurrency=max_concurrency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the generated data into training format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_simple_qa_dataset(generated_data: Dataset) -> Dataset:\n",
    "    seen = set()\n",
    "    messages_list: list[dict] = []\n",
    "    for generated_data_i in generated_data:\n",
    "        user = generated_data_i['question']\n",
    "        assistant = generated_data_i['response']\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "            {\"role\": \"assistant\", \"content\": assistant},\n",
    "        ]\n",
    "        # deduplicate messages\n",
    "        key = tuple([frozenset(d.items()) for d in messages])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            messages_list.append({\"messages\": messages})\n",
    "    messages_data = Dataset.from_list(messages_list)\n",
    "    return messages_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "messages_data = create_simple_qa_dataset(generated_data)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "messages_data.to_json(f\"{output_dir}/messages_data.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_hub-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
